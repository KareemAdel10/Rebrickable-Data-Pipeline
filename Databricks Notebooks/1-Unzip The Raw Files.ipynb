{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85ce3b21-f4f4-48e4-a321-6545aac139b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 1. Unzip The Raw Files that are found in 'raw-data' into 'Unzipped Rebrickable'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76e51098-6a2f-4c77-b65b-6a71deafafd4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # Azure storage account details\n",
    "account_name = \"***********\"\n",
    "account_key = \"******************\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f389f650-a7a6-48c0-a302-b455fd0bb778",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from datetime import datetime\n",
    "import gzip\n",
    "import io\n",
    "from pyspark.sql.functions import col\n",
    "import pandas as pd\n",
    "\n",
    "spark.conf.set(f\"fs.azure.account.key.{account_name}.dfs.core.windows.net\", account_key)\n",
    "\n",
    "# Set today's date dynamically\n",
    "today = datetime.today()\n",
    "year = today.strftime('%Y')\n",
    "month = today.strftime('%m')\n",
    "day = today.strftime('%d')\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ADLS Integration\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b1f9524-8d82-45c4-abc9-94299a1f600f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def read_and_unzip_csv(file_path):\n",
    "    \"\"\"\n",
    "    Function to read and unzip a gzip-compressed CSV file from that are found in raw-data/Rebricable/... and saved into raw-data/Unzipped Rebrickable/...\n",
    "    \"\"\"\n",
    "    compressed_data = spark.read.format(\"binaryFile\").load(file_path).collect()[0].content\n",
    "    \n",
    "    with gzip.GzipFile(fileobj=io.BytesIO(compressed_data)) as gz:\n",
    "        uncompressed_data = gz.read().decode('utf-8')  \n",
    "\n",
    "    data = io.StringIO(uncompressed_data)\n",
    "    df = pd.read_csv(data)  \n",
    "\n",
    "    spark_df = spark.createDataFrame(df)\n",
    "    return spark_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "261e5407-91dd-49e5-9ec1-701d4175ec91",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to read: abfss://raw-data@atomicatraining.dfs.core.windows.net/Rebrickable/Lego/themes/Year=2024/Month=11/Day=08/themes.csv.gz\nSuccessfully saved themes DataFrame as abfss://raw-data@atomicatraining.dfs.core.windows.net/Unzipped Rebrickable/Lego/themes/Year=2024/Month=11/Day=08/themes.csv\nAttempting to read: abfss://raw-data@atomicatraining.dfs.core.windows.net/Rebrickable/Lego/colors/Year=2024/Month=11/Day=08/colors.csv.gz\nSuccessfully saved colors DataFrame as abfss://raw-data@atomicatraining.dfs.core.windows.net/Unzipped Rebrickable/Lego/colors/Year=2024/Month=11/Day=08/colors.csv\nAttempting to read: abfss://raw-data@atomicatraining.dfs.core.windows.net/Rebrickable/Lego/part_categories/Year=2024/Month=11/Day=08/part_categories.csv.gz\nSuccessfully saved part_categories DataFrame as abfss://raw-data@atomicatraining.dfs.core.windows.net/Unzipped Rebrickable/Lego/part_categories/Year=2024/Month=11/Day=08/part_categories.csv\nAttempting to read: abfss://raw-data@atomicatraining.dfs.core.windows.net/Rebrickable/Lego/parts/Year=2024/Month=11/Day=08/parts.csv.gz\nSuccessfully saved parts DataFrame as abfss://raw-data@atomicatraining.dfs.core.windows.net/Unzipped Rebrickable/Lego/parts/Year=2024/Month=11/Day=08/parts.csv\nAttempting to read: abfss://raw-data@atomicatraining.dfs.core.windows.net/Rebrickable/Lego/part_relationships/Year=2024/Month=11/Day=08/part_relationships.csv.gz\nSuccessfully saved part_relationships DataFrame as abfss://raw-data@atomicatraining.dfs.core.windows.net/Unzipped Rebrickable/Lego/part_relationships/Year=2024/Month=11/Day=08/part_relationships.csv\nAttempting to read: abfss://raw-data@atomicatraining.dfs.core.windows.net/Rebrickable/Lego/elements/Year=2024/Month=11/Day=08/elements.csv.gz\nSuccessfully saved elements DataFrame as abfss://raw-data@atomicatraining.dfs.core.windows.net/Unzipped Rebrickable/Lego/elements/Year=2024/Month=11/Day=08/elements.csv\nAttempting to read: abfss://raw-data@atomicatraining.dfs.core.windows.net/Rebrickable/Lego/sets/Year=2024/Month=11/Day=08/sets.csv.gz\nSuccessfully saved sets DataFrame as abfss://raw-data@atomicatraining.dfs.core.windows.net/Unzipped Rebrickable/Lego/sets/Year=2024/Month=11/Day=08/sets.csv\nAttempting to read: abfss://raw-data@atomicatraining.dfs.core.windows.net/Rebrickable/Lego/minifigs/Year=2024/Month=11/Day=08/minifigs.csv.gz\nSuccessfully saved minifigs DataFrame as abfss://raw-data@atomicatraining.dfs.core.windows.net/Unzipped Rebrickable/Lego/minifigs/Year=2024/Month=11/Day=08/minifigs.csv\nAttempting to read: abfss://raw-data@atomicatraining.dfs.core.windows.net/Rebrickable/Lego/inventories/Year=2024/Month=11/Day=08/inventories.csv.gz\nSuccessfully saved inventories DataFrame as abfss://raw-data@atomicatraining.dfs.core.windows.net/Unzipped Rebrickable/Lego/inventories/Year=2024/Month=11/Day=08/inventories.csv\nAttempting to read: abfss://raw-data@atomicatraining.dfs.core.windows.net/Rebrickable/Lego/inventory_parts/Year=2024/Month=11/Day=08/inventory_parts.csv.gz\nSuccessfully saved inventory_parts DataFrame as abfss://raw-data@atomicatraining.dfs.core.windows.net/Unzipped Rebrickable/Lego/inventory_parts/Year=2024/Month=11/Day=08/inventory_parts.csv\nAttempting to read: abfss://raw-data@atomicatraining.dfs.core.windows.net/Rebrickable/Lego/inventory_sets/Year=2024/Month=11/Day=08/inventory_sets.csv.gz\nSuccessfully saved inventory_sets DataFrame as abfss://raw-data@atomicatraining.dfs.core.windows.net/Unzipped Rebrickable/Lego/inventory_sets/Year=2024/Month=11/Day=08/inventory_sets.csv\nAttempting to read: abfss://raw-data@atomicatraining.dfs.core.windows.net/Rebrickable/Lego/inventory_minifigs/Year=2024/Month=11/Day=08/inventory_minifigs.csv.gz\nSuccessfully saved inventory_minifigs DataFrame as abfss://raw-data@atomicatraining.dfs.core.windows.net/Unzipped Rebrickable/Lego/inventory_minifigs/Year=2024/Month=11/Day=08/inventory_minifigs.csv\nAttempting to read: abfss://raw-data@atomicatraining.dfs.core.windows.net/Rebrickable/Lego/elements/Year=2024/Month=11/Day=08/elements.csv.gz\nSuccessfully saved elements DataFrame as abfss://raw-data@atomicatraining.dfs.core.windows.net/Unzipped Rebrickable/Lego/elements/Year=2024/Month=11/Day=08/elements.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset_names = [\"themes\", \"colors\", \"part_categories\", \"parts\", \"part_relationships\", \"elements\", \"sets\", \n",
    "                 \"minifigs\", \"inventories\", \"inventory_parts\", \"inventory_sets\", \"inventory_minifigs\", \"elements\"]\n",
    "                 \n",
    "# Loop through each dataset and read the unzipped data and rename it\n",
    "for dataset in dataset_names:\n",
    "    # Define the file path for the compressed CSV file\n",
    "    file_path = f\"abfss://raw-data@{account_name}.dfs.core.windows.net/Rebrickable/Lego/{dataset}/Year={year}/Month={month}/Day={day}/{dataset}.csv.gz\"\n",
    "    \n",
    "    # Define the target directory for saving unzipped CSV files\n",
    "    target_dir = f\"abfss://raw-data@{account_name}.dfs.core.windows.net/Unzipped Rebrickable/Lego/{dataset}/Year={year}/Month={month}/Day={day}\"\n",
    "    \n",
    "    # Define the final output path for the renamed file\n",
    "    final_output_path = f\"{target_dir}/{dataset}.csv\"\n",
    "\n",
    "    print(f\"Attempting to read: {file_path}\")\n",
    "\n",
    "    try:\n",
    "        df = read_and_unzip_csv(file_path)\n",
    "\n",
    "        # Save the DataFrame as a CSV file to a temporary directory\n",
    "        temp_dir = f\"{target_dir}/temp\"\n",
    "        df.coalesce(1).write.mode(\"overwrite\").csv(temp_dir, header=True)\n",
    "        \n",
    "        files_in_temp = dbutils.fs.ls(temp_dir)\n",
    "        \n",
    "        # Find the part file in the temporary directory and rename it\n",
    "        part_file = [f.path for f in files_in_temp if f.name.startswith(\"part-\")][0]\n",
    "        dbutils.fs.mv(part_file, final_output_path)\n",
    "        \n",
    "        dbutils.fs.rm(temp_dir, True)\n",
    "\n",
    "        print(f\"Successfully saved {dataset} DataFrame as {final_output_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading or saving {file_path}: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "1-Unzip The Raw Files",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
